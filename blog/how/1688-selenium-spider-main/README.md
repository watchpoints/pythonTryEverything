# 1688爬虫(基于selenium)

## 项目概述：
通过搜索关键词采用selenium+selenium日志hook(亮点：自行查找相关功能,实现所有请求包括ajax动态请求的监听)爬取指定页数的商品信息，包括公司名，五项评分，综合评分，价格，所有宝贝图的图片，以及产品的规格，尺寸暂时没写。

不足之处：验证码，已经写了ip切换的功能，暂时没找到合适的ip池，需要的自行根据代码将注释取消启用，并且修改ip.txt的内容即可，ip通过http https 地址+端口直连的方式连接。在爬取频繁之后，一般是十个商品会出现一次验证码，目前采用的方式是在电脑人工切换ip刷新页面。数量不多的话影响不大。

## 项目更新说明：

### 第三版更新说明:
优化了程序，使之能完整的运行。

未来可以继续优化的步骤：效率高于扫码登录的更优方式，ip验证问题（遇到ip验证需要人力解决）

### 第二版更新说明:
- 修改了退换体验分数为空时存表为-1的错误
- 修改了成交额显示错误的问题
- 美化了下代码

## 需求分析
- 分析商品页ajax链接（下的）存储到{keyword}_{sort_type}.csv 中 (此功能在py爬虫文件均自动重新生成)

## 主要代码实现

## 其他描述：
- 直接运行主文件

## 测试：
cookies容易失效，后续考虑多账号轮番登录，登录暂时需要人工

## 配置：
略 

## 安装包：
目录下 requirements.txt文件 

打开当前目录的dos窗口，输入:
```
pip install -r requirements.txt
```

本代码仅供个人参考交流探讨更优方案等。
